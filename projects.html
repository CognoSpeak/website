---
layout: default
---

<!-- Main -->
<section id="main" class="wrapper style1">
    <header class="major">
        <h2>CognoSpeak&trade; Projects</h2>
        <!--  <p>Tempus adipiscing commodo ut aliquam blandit</p> -->
    </header>
    <div class="container">

        <section>
            <h3>COMPutational Assessment of Stroke Survivors (COMPASS)</h3>

            <p> <b>Background & Significance</b> Stroke affects 152,000 UK citizens every year. Over 50% of stroke
                survivors have cognitive impairment. Currently 850,000 people live with dementia in the UK and stroke is
                one
                of the biggest risk factors. National guidelines promote early cognitive testing on all people who have
                had
                a stroke. However, current pen-and-paper based tests are not always appropriate for stroke survivors who
                often have motor, visual or language difficulties. In addition, longitudinal follow-up is required to
                detect
                emerging cognitive impairment. Finally, assessments typically take place in hospital settings, are
                costly
                and often inconvenient for patients.

                <b>Aim & Objectives</b> This project aims to create an easy-to-use cognitive assessment tool
                specifically
                designed for the needs of stroke survivors. It will be based on our stratification tool COCOA
                (COmputational
                COgnitive Assessment), developed for detecting early signs of dementia. The tool uses automatic analysis
                of
                conversations that patients have with an on-screen digital doctor. This includes verbal fluency and a
                picture description task. The conversation and responses to questions are analysed for signs of
                cognitive
                decline using speech recognition and machine learning classification. We have demonstrated high
                stratification accuracy in distinguishing between healthy controls, people with mild cognitive
                impairment
                (MCI) and people with Alzheimer’s disease. Feedback suggests that patients find the system
                straightforward
                and pleasant to use.

                <em>This project was funding by the 2019 <a href="https://rosetreestrust.co.uk/">Rosetrees Trust</a>
                    Prize
                    in Medicine and AI</em>. 2020-2023.
            </p>

            <h3>Training Network on Processing of Pathological Speech (TAPAS)</h3>

            <p>
                There are an increasing number of people across Europe with debilitating speech pathologies (e.g., due
                to stroke, Parkinson’s, etc). These groups face communication problems that can lead to social
                exclusion. They are now being further marginalised by a new wave of speech technology that is
                increasingly woven into everyday life but which is not robust to atypical speech. TAPAS is a Horizon
                2020 Marie Skłodowska-Curie Actions Innovative Training Network European Training Network (MSCA-ITN-ETN)
                project that aims to transform the well being of these people.</p>

            <p>The <a href="tapas-etn-eu.org">TAPAS</a> work programme targets three key research problems:

                <b>Detection:</b> We will develop speech processing techniques for early detection of conditions that
                impact on
                speech production. The outcomes will be cheap and non-invasive diagnostic tools that provide early
                warning of the onset of progressive conditions such as Alzheimer’s and Parkinson’s.</p>

            <p><b>Therapy:</b> We will use newly-emerging speech processing techniques to produce automated speech
                therapy
                tools. These tools will make therapy more accessible and more individually targeted. Better therapy can
                increase the chances of recovering intelligible speech after traumatic events such a stroke or oral
                surgery.</p>

            <p><b>Assisted Living:</b> We will re-design current speech technology so that it works well for people
                with
                speech impairments and also helps in making informed clinical choices. People with speech impairments
                often have other co-occurring conditions making them reliant on carers. Speech-driven tools for
                assisted-living are a way to allow such people to live more independently.</p>

            <p>TAPAS adopts an inter-disciplinary and multi-sectorial approach. The consortium includes clinical
                practitioners, academic researchers and industrial partners, with expertise spanning speech engineering,
                linguistics and clinical science. All members have expertise in some element of pathological speech.
                This rich network will train a new generation of 15 researchers, equipping them with the skills and
                resources necessary for lasting success.
                There are a total of 15 ESRs on TAPAS, two of whom are working in Sheffield. 2017-2021.</p>

            </p>

            <h3>Health & Care Partnership: Remote monitoring people with Mild Cognitive Impairment using combined
                technology of the Digital Doctor and ViVA</h3>
            <p>

                This project will investigate whether OTs can assess PwMCI in their own home using CognoSpeak in
                combination with the ViVA remote visit system. PwMCI would use their own smartphone or tablet
                (facilitated by support worker or family member) or have one provided.

                In a recent stakeholder, patient and public consultation the opportunity to utilise technology to
                minimise hospital attendance and bring care closer to home was viewed positively.

                We will run workshops involving all end-users on what is required to use technology to manage PwMCI
                remotely. We will recruit 10 PwMCI to use this system in a real clinical setting from the two hospital
                memory clinics in Sheffield.

                This is a new collaboration between STH, SHSCT, TUoS, SHU, Sheffield City Council and Age UK. 2019-2020.
            </p>

            <h3>Automatic Dementia Detection in Kenya</h3>

            <p><b>Project Description</b>

                We have developed two independent projects that are low­ cost non- invasive techniques to measure
                cognitive function. One utilises Quantitative EEG and one uses a virtual doctor that analyses speech
                using automatic speech recognition. Both use machine learning algorithms to distinguish Alzheimer’s
                disease. This project funded a feasibility study in Nairobi, Kenya for a data recording and feasibility
                study. It was funded by a UoS GRCP pump priming grant. 2019.
            </p>

            <h3>COmputational COgnitive Assessment (COCOA)</h3>
            <p>This project developed and evaluated a system for automatic assessment of a person’s cognitive impairment
                based on how they interact with an on-screen digital doctor virtual agent. It was funded by a MRC
                Confidence in Concept grant, 2017-2018.
            </p>
            <h3>COMPutational Assessment of Stroke Survivors Prototype (COMPASS-proto)</h3>
            <p>This project aimed to create an easy-to-use cognitive assessment tool specifically designed for the needs
                of
                stroke survivors. It was based on the development in COCOA (COmputational COgnitive Assessment),
                of a tool for detecting early signs of dementia. The tool uses automatic analysis of conversations that
                patients have with an on-screen digital doctor. The patients’ speech is and analysed for signs of
                cognitive
                decline using speech recognition and machine learning classification. Funded by the FAST Healthcare
                NetworksPlus Project. 2019
            </p>

        </section>

</section>